{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/taxi.csv', index_col=[0], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.resample('1H').sum()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(data):\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['hour'] = data.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_orders'].resample('M').sum().plot()\n",
    "\n",
    "plt.title('Number of Monthly Orders')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_orders'].resample('M').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When grouped by month, there is a clear upward trend in the number of orders over the six-month period. Each subsequent month shows an increase in the total number of orders compared to the previous month.\n",
    "\n",
    "August 2018 saw the highest number of orders, with a total of 94,973 orders. This is more than double the number of orders in March 2018, indicating a significant increase in demand or activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data['num_orders']['2018-03-01'].plot(label='2018-03-01')\n",
    "data['num_orders']['2018-03-02'].plot(label='2018-03-02')\n",
    "data['num_orders']['2018-03-03'].plot(label='2018-03-03')\n",
    "\n",
    "plt.title('Number of Orders for March 01-03')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data['num_orders']['2018-05-01'].plot(label='2018-05-01')\n",
    "data['num_orders']['2018-05-02'].plot(label='2018-05-02')\n",
    "data['num_orders']['2018-05-03'].plot(label='2018-05-03')\n",
    "\n",
    "plt.title('Number of Orders for May 01-03')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orders consistently start relatively high at midnight and gradually decrease until the early morning hours. There are notable peaks in orders between 8 AM to 11 AM. Order numbers fluctuate throughout the afternoon and early evening hours, with occasional peaks and dips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['hour'] == 0]['num_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data[data['hour'] == 0]['num_orders']['2018-03'].plot()\n",
    "\n",
    "plt.title('Number of Orders at 12AM for 2018-03')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of Orders')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the number of orders placed at 12AM in the month of March, we see a noticable dip on March 06. We will analyze that day below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data['num_orders']['2018-03-06'].plot()\n",
    "\n",
    "plt.title('Number of Orders for 2018-03-06')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of Orders')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the low amount of orders for 12AM on March 06th, the trends are consistent with the other days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data[data['hour'] == 0]['num_orders']['2018-04'].plot()\n",
    "\n",
    "plt.title('Number of Orders at 12AM for 2018-04')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number of Orders')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(data['num_orders']['2018-03-01':'2018-03-07'])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(311)\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Seasonality')\n",
    "plt.subplot(313)\n",
    "decomposed.resid.plot(ax=plt.gca())\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing the first week of March, despite fluctuations in trends, there is a consistent pattern in a 24H cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(data['num_orders']['2018-04-01':'2018-04-29'])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(311)\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Seasonality')\n",
    "plt.subplot(313)\n",
    "decomposed.resid.plot(ax=plt.gca())\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the month of April, we see similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(data['num_orders'])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(311)\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Trend')\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal.plot(ax=plt.gca())\n",
    "plt.title('Seasonality')\n",
    "plt.subplot(313)\n",
    "decomposed.resid.plot(ax=plt.gca())\n",
    "plt.title('Residuals')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis, there seems to be seasonality to a 24 hour day, while the number of orders trends up as months go by."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, shuffle=False, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationarityTest = adfuller(train['num_orders'], autolag='AIC')\n",
    "print(\"P-value: \", df_stationarityTest[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Median hourly number of orders:', train['num_orders'].median())\n",
    "\n",
    "pred_previous = test['num_orders'].shift()\n",
    "pred_previous.iloc[0] = train['num_orders'].iloc[-1]\n",
    "print('RMSE:', np.sqrt(mean_squared_error(test['num_orders'], pred_previous)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lag = None\n",
    "use_seasonality = None\n",
    "best_ar_rmse = float('inf')\n",
    "best_ar_pred = None\n",
    "\n",
    "lags = [10, 50, 100]\n",
    "seasonality = [True, False]\n",
    "\n",
    "for lag in lags:\n",
    "    for seasonal in seasonality:\n",
    "        \n",
    "        mod = ar_select_order(endog=train['num_orders'], maxlag=lag)\n",
    "        ar_order = mod.ar_lags\n",
    "\n",
    "        ar_model = AutoReg(train['num_orders'], lags=ar_order, seasonal=seasonal)\n",
    "        ar_model = ar_model.fit()\n",
    "\n",
    "        start_value = len(train['num_orders'])\n",
    "        end_value = len(train['num_orders']) + len(test['num_orders']) - 1\n",
    "        ar_pred = ar_model.predict(start=start_value, end=end_value, dynamic=False)\n",
    "\n",
    "        ar_rmse = np.sqrt(mean_squared_error(test['num_orders'], ar_pred))\n",
    "        print(f'RMSE: {ar_rmse}')\n",
    "        \n",
    "        if ar_rmse < best_ar_rmse:\n",
    "            best_lag = ar_order\n",
    "            use_seasonality = seasonal\n",
    "            best_ar_rmse = ar_rmse\n",
    "            best_ar_pred = ar_pred\n",
    "            \n",
    "print('Optimal Lags:', best_lag)\n",
    "print('Uses seasonal:', use_seasonality)\n",
    "print('Best AR RMSE:', best_ar_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_ar_pred, color='blue', label='pred')\n",
    "plt.plot(test['num_orders'], color='red', label='test')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ma_order_range = [10, 20, 30]\n",
    "\n",
    "best_ma_rmse = float('inf')\n",
    "best_ma_order = None\n",
    "\n",
    "for max_ma_order in max_ma_order_range:\n",
    "    res = arma_order_select_ic(y=train['num_orders'], max_ar=0, max_ma=max_ma_order)\n",
    "    ma_order = res.bic_min_order[1]\n",
    "    \n",
    "    ma_model = ARIMA(train['num_orders'], order=(0, 0, ma_order))\n",
    "    ma_model = ma_model.fit()\n",
    "    \n",
    "    start_value = len(train['num_orders'])\n",
    "    end_value = len(train['num_orders']) + len(test['num_orders']) - 1\n",
    "    ma_pred = ma_model.predict(start=start_value, end=end_value, dynamic=False)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(test['num_orders'], ma_pred))\n",
    "    print(f'Max MA Order: {max_ma_order}, MA Order: {ma_order}, RMSE: {rmse}')\n",
    "    \n",
    "    if rmse < best_ma_rmse:\n",
    "        best_ma_rmse = rmse\n",
    "        best_ma_order = ma_order\n",
    "\n",
    "print(f'Best RMSE: {best_ma_rmse}')\n",
    "print(f'Best MA Order: {best_ma_order}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA/ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/taxi.csv', index_col=[0], parse_dates=[0])\n",
    "data = data.resample('1H').sum()\n",
    "train, test = train_test_split(data, shuffle=False, test_size=0.10)\n",
    "\n",
    "ar_order_range = [1, 2, 3]\n",
    "diff_order_range = [0, 1]\n",
    "ma_order_range = [1, 2, 3]\n",
    "\n",
    "best_arima_rmse = float('inf')\n",
    "best_ar_order = None\n",
    "best_diff_order = None\n",
    "best_ma_order = None\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for ar_order in ar_order_range:\n",
    "    for diff_order in diff_order_range:\n",
    "        for ma_order in ma_order_range:\n",
    "            try:\n",
    "                cv_rmse_list = []\n",
    "\n",
    "                for train_index, val_index in tscv.split(train['num_orders']):\n",
    "                    train_cv, val_cv = train.iloc[train_index], train.iloc[val_index]\n",
    "\n",
    "                    arima_model = ARIMA(train_cv, order=(ar_order, diff_order, ma_order))\n",
    "                    arima_model_fit = arima_model.fit()\n",
    "\n",
    "                    start_value = len(train_cv)\n",
    "                    end_value = len(train_cv) + len(val_cv) - 1\n",
    "                    arima_pred = arima_model_fit.predict(start=start_value, end=end_value, dynamic=False)\n",
    "\n",
    "                    rmse = np.sqrt(mean_squared_error(val_cv, arima_pred))\n",
    "                    cv_rmse_list.append(rmse)\n",
    "\n",
    "                avg_rmse = np.mean(cv_rmse_list)\n",
    "                print(f'AR Order: {ar_order}, Diff Order: {diff_order}, MA Order: {ma_order}, Avg CV RMSE: {avg_rmse}')\n",
    "\n",
    "                if avg_rmse < best_arima_rmse:\n",
    "                    best_arima_rmse = avg_rmse\n",
    "                    best_ar_order = ar_order\n",
    "                    best_diff_order = diff_order\n",
    "                    best_ma_order = ma_order\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Error with parameters AR: {ar_order}, I: {diff_order}, MA: {ma_order} - {e}')\n",
    "\n",
    "print(f'Best RMSE: {best_arima_rmse}')\n",
    "print(f'Best AR Order: {best_ar_order}')\n",
    "print(f'Best Diff Order: {best_diff_order}')\n",
    "print(f'Best MA Order: {best_ma_order}')\n",
    "\n",
    "best_arima_model = ARIMA(train['num_orders'], order=(best_ar_order, best_diff_order, best_ma_order))\n",
    "best_arima_model_fit = best_arima_model.fit()\n",
    "\n",
    "start_value = len(train['num_orders'])\n",
    "end_value = len(train['num_orders']) + len(test['num_orders']) - 1\n",
    "test_predictions = best_arima_model_fit.predict(start=start_value, end=end_value, dynamic=False)\n",
    "\n",
    "arima_rmse = np.sqrt(mean_squared_error(test['num_orders'], test_predictions))\n",
    "print(f'Test RMSE: {arima_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 24))\n",
    "sarima_model_fit = sarima_model.fit(disp=False)\n",
    "\n",
    "start_value = len(train['num_orders'])\n",
    "end_value = len(train['num_orders']) + len(test['num_orders']) - 1\n",
    "sarima_pred = sarima_model_fit.predict(start=start_value, end=end_value, dynamic=False)\n",
    "\n",
    "plt.plot(test.index, sarima_pred, color='blue', label='Predictions')\n",
    "plt.plot(test.index, test, color='red', label='Actual')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "sarima_rmse = np.sqrt(mean_squared_error(test, sarima_pred))\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ar_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ma_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the various models with different hyperparameters, the SARIMA Model stands out as the most accurate with an RMSE of 44.\n",
    "\n",
    "The AR model had a decent score, at 48.33, however missed the target RMSE.\n",
    "\n",
    "The ARIMA Model had similar results, with a high training RMSE of 36, but when tested reached 64."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
