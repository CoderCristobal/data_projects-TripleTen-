{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sure Tomorrow insurance company wants to solve several tasks with the help of Machine Learning and you are asked to evaluate that possibility.\n",
    "\n",
    "Task 1: Find customers who are similar to a given customer. This will help the company's agents with marketing.\n",
    "Task 2: Predict whether a new customer is likely to receive an insurance benefit. Can a prediction model do better than a dummy model?\n",
    "Task 3: Predict the number of insurance benefits a new customer is likely to receive using a linear regression model.\n",
    "Task 4: Protect clients' personal data without breaking the model from the previous task. It's necessary to develop a data transformation algorithm that would make it hard to recover personal information if the data fell into the wrong hands. This is called data masking, or data obfuscation. But the data should be protected in such a way that the quality of machine learning models doesn't suffer. You don't need to pick the best model, just prove that the algorithm works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems fine with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it is a bit difficult to spot obvious groups (clusters) as it is difficult to combine several variables simultaneously (to analyze multivariate distributions). That's where LA and ML can be quite handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Statistical Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns k nearest neighbors\n",
    "\n",
    "    :param df: pandas DataFrame used to find similar objects within\n",
    "    :param n: object no for which the nearest neighbours are looked for\n",
    "    :param k: the number of the nearest neighbours to return\n",
    "    :param metric: name of distance metric\n",
    "    \"\"\"\n",
    "\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k, metric=metric)\n",
    "    nbrs.fit(df[feature_names])\n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = get_knn(df, 0, 10, 'euclidean')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = get_knn(df, 0, 10, 'manhattan')\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = get_knn(df_scaled, 0, 10, 'euclidean')\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = get_knn(df_scaled, 0, 10, 'manhattan')\n",
    "print(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the target\n",
    "\n",
    "df['insurance_benefits_received'] = (df['insurance_benefits'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled['insurance_benefits_received'] = (df_scaled['insurance_benefits'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the class imbalance with value_counts()\n",
    "\n",
    "class_imbalance = df['insurance_benefits_received'].value_counts()\n",
    "print(class_imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# if you have an issue with the following line, restart the kernel and run the notebook again\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Confusion Matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating output of a random model\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "    print(f'The probability: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, size=len(df))\n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df_scaled['insurance_benefits_received'].sum() / len(df_scaled), 0.5, 1]:\n",
    "    print(f'The probability: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, size=len(df_scaled))\n",
    "    eval_classifier(df_scaled['insurance_benefits_received'], y_pred_rnd)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['insurance_benefits_received', 'insurance_benefits'])\n",
    "target = df['insurance_benefits_received']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores_original = []\n",
    "f1_scores_scaled = []\n",
    "\n",
    "# Loop through different values of k for kNN\n",
    "for k in range(1, 11):\n",
    "    # kNN classifier for original data\n",
    "    knn_original = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_original.fit(features_train, target_train)\n",
    "    \n",
    "    target_pred_original = knn_original.predict(features_test)\n",
    "    \n",
    "    f1_original = sklearn.metrics.f1_score(target_test, target_pred_original)\n",
    "    f1_scores_original.append(f1_original)\n",
    "\n",
    "    # kNN classifier for scaled data\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    \n",
    "    features_train_scaled = scaler.fit_transform(features_train)\n",
    "    features_test_scaled = scaler.transform(features_test)\n",
    "    \n",
    "    knn_scaled = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_scaled.fit(features_train_scaled, target_train)\n",
    "    \n",
    "    target_pred_scaled = knn_scaled.predict(features_test_scaled)\n",
    "    \n",
    "    f1_scaled = sklearn.metrics.f1_score(target_test, target_pred_scaled)\n",
    "    f1_scores_scaled.append(f1_scaled)\n",
    "    \n",
    "print('F1 scores for original DF:')\n",
    "print(f1_scores_original)\n",
    "\n",
    "print()\n",
    "\n",
    "print('F1 scores for scaled DF:')\n",
    "print(f1_scores_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the dataset has led to a substantial improvement in the F1 scores across all metrics. In the original dataset, the F1 scores ranged from 0.0245 to 0.6523, indicating relatively poor performance. After scaling, the F1 scores improved dramatically, ranging from 0.9128 to 0.9393, indicating that the model's performance is significantly better and more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # adding the unities\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        self.weights = np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(y)\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # adding the unities\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        y_pred = X2.dot(self.weights)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age', 'gender', 'income', 'family_members']]\n",
    "y = df['insurance_benefits']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "print()\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "print(lr.weights)\n",
    "print()\n",
    "\n",
    "y_testscaled_pred = lr.predict(X_test_scaled)\n",
    "eval_regressor(y_test, y_testscaled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference in the RMSE and R2 scores between scaled and unscaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to compute the inverse\n",
    "try:\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    print(\"Matrix P is invertible.\")\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"Matrix P is not invertible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_obfuscated = np.dot(X, P)\n",
    "X_obfuscated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_inv = np.linalg.inv(P)\n",
    "\n",
    "X_recovered = np.dot(X_obfuscated, P_inv)\n",
    "\n",
    "print(\"Recovered Data (X_recovered):\")\n",
    "print(X_recovered[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered = pd.DataFrame(X_recovered, columns=personal_info_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_obfuscated = pd.DataFrame(X_obfuscated, columns=personal_info_column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_obfuscated[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    P_inv = np.linalg.inv(P)\n",
    "    print(\"Matrix P is invertible.\")\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"Matrix P is not invertible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def fit(self, train_features, train_target):\n",
    "        X = np.concatenate((np.ones((train_features.shape[0], 1)), train_features), axis=1)\n",
    "        y = train_target\n",
    "        w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "        self.w = w[1:]\n",
    "        self.w0 = w[0]\n",
    "\n",
    "    def predict(self, test_features):\n",
    "        return test_features.dot(self.w) + self.w0\n",
    "    \n",
    "model = LinearRegression()\n",
    "model.fit(features, target)\n",
    "predictions = model.predict(features)\n",
    "print(r2_score(target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObfuscatingLinearRegression:\n",
    "    def __init__(self, obfuscate=False, noise_level=0.1):\n",
    "        self.obfuscate = obfuscate\n",
    "        self.noise_level = noise_level\n",
    "        self.model = sklearn.linear_model.LinearRegression()\n",
    "        self.P = None\n",
    "\n",
    "    def generate_invertible_matrix(self, size):\n",
    "        while True:\n",
    "            P = np.random.rand(size, size)\n",
    "            try:\n",
    "                _ = np.linalg.inv(P)\n",
    "                return P\n",
    "            except numpy.linalg.LinAlgError:\n",
    "                continue\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.obfuscate:\n",
    "            if self.P is None:\n",
    "                self.P = self.generate_invertible_matrix(X.shape[1])\n",
    "            X = X @ self.P\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, features):\n",
    "        if self.obfuscate and self.P is not None:\n",
    "            features = features @ self.P\n",
    "        return self.model.predict(features)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        mse = sklearn.metrics.mean_squared_error(y, y_pred)\n",
    "        r2 = sklearn.metrics.r2_score(y, y_pred)\n",
    "        return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_original = ObfuscatingLinearRegression(obfuscate=False)\n",
    "model_obfuscated = ObfuscatingLinearRegression(obfuscate=True)\n",
    "\n",
    "model_original.fit(X_train, y_train)\n",
    "model_obfuscated.fit(X_train, y_train)\n",
    "\n",
    "predictions_original = model_original.predict(X_test)\n",
    "predictions_obfuscated = model_obfuscated.predict(X_test)\n",
    "\n",
    "mse_original, r2_original = model_original.score(X_test, y_test)\n",
    "mse_obfuscated, r2_obfuscated = model_obfuscated.score(X_test, y_test)\n",
    "\n",
    "print(f\"Original Data - MSE: {mse_original}, R2: {r2_original}\")\n",
    "print(f\"Obfuscated Data - MSE: {mse_obfuscated}, R2: {r2_obfuscated}\")\n",
    "print(f\"Difference in Predictions: {np.mean(predictions_original - predictions_obfuscated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions_original).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results, it seems like obfuscating the feature matrix 𝑋 with matrix 𝑃 didn't noticeably affect how well the linear regression model performed. The original and obfuscated models had almost identical MSE and R² scores, and their predictions differed by an insignificant amount. This suggests that Linear Regression handles this type of obfuscation well from a computational perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model has been made that retains accuracy after scaling and obscufation. The MSE suggests low prediction error, while the 𝑅2 score indicates a moderate level of goodness-of-fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
